{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 12: Trainieren eins verschlüsselten NN auf verschlüsselten Daten\n",
    "\n",
    "In diesem Notebook werden alle bisher erarbeiteten Techniken zusammengeführt um ein verschlüsseltes Neuronales Netzwerk auf verschlüsselten Daten zu trainieren und mit ihm Vorhersagen zu tätigen. \n",
    "\n",
    "Insbesondere wird dabei die \"Autograd-Engine\" vorgestellt, welche verschlüsselte Berechnungen durchführen kann.\n",
    "\n",
    "Autoren:\n",
    "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)\n",
    "- Jason Paumier - Github: [@Jasopaum](https://github.com/Jasopaum)\n",
    "- Théo Ryffel - Twitter: [@theoryffel](https://twitter.com/theoryffel)\n",
    "\n",
    "Übersetzer:\n",
    "- Jan Moritz Behnken - Github: [@JMBehnken](https://github.com/JMBehnken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 1: Erstellen der Helfer und des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T11:37:11.289086Z",
     "start_time": "2020-04-04T11:37:09.695010Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T11:37:12.371828Z",
     "start_time": "2020-04-04T11:37:11.908472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set everything up\n",
    "hook = sy.TorchHook(torch) \n",
    "\n",
    "alice = sy.VirtualWorker(id=\"alice\", hook=hook)\n",
    "bob = sy.VirtualWorker(id=\"bob\", hook=hook)\n",
    "james = sy.VirtualWorker(id=\"james\", hook=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T11:37:15.866937Z",
     "start_time": "2020-04-04T11:37:15.847691Z"
    }
   },
   "outputs": [],
   "source": [
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]])\n",
    "target = torch.tensor([[0],[0],[1],[1.]])\n",
    "\n",
    "# A Toy Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 2: Verschlüsseln des Models und der Daten\n",
    "\n",
    "Die Verschlüsselung geschieht hier in zwei Schritten. Weil \"Secure Multi-Party Computation\" nur mit Integern funktionert, müssen alle Dezimalzahlen (wie z. B. die Gewichte und Aktivierungsfunktionen) mit festgelegter Genauigkeit umgewandelt werden. Dafür wird die Funktion `.fix_precision()` verwendet.\n",
    "\n",
    "Daraufhin kann `.share()` wie auch in den vorherigen Tutorials verwendet werden, um die Tensoren auf Alice und Bob verschlüsselt aufzuteilen. Zu beachten ist, dass `requires_grad` auf `True` gesetzt werden muss. Dadurch wird eine spezielle Autograd Methode zu den verschlüsselten Daten hinzugefügt. Tatsächlich kann das normale Autograd von PyTorch wegen den Integern der \"Secure Multi-Party Computation\" nicht verwendet werden. Aus diesem Grund muss ein spezialisierter AutogradTensor-Knoten eingefügt werden, welcher für das Backpropagieren die Gradienten berechnet. Jedes Element kann begutachtet werden, um den enthaltenen AutogradTensor zu betrachten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T12:19:42.710982Z",
     "start_time": "2020-04-04T12:19:42.653189Z"
    }
   },
   "outputs": [],
   "source": [
    "# We encode everything\n",
    "data = data.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "target = target.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "model = model.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T12:19:43.953407Z",
     "start_time": "2020-04-04T12:19:43.945660Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 3: Training\n",
    "\n",
    "Das Netzwerk kann nun mit simpler Tensor-Logik trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T12:20:32.546878Z",
     "start_time": "2020-04-04T12:20:23.961847Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = optim.SGD(params=model.parameters(),lr=0.1).fix_precision()\n",
    "\n",
    "for iter in range(20):\n",
    "    # 1) erase previous gradients (if they exist)\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # 2) make a prediction\n",
    "    pred = model(data)\n",
    "\n",
    "    # 3) calculate how much we missed\n",
    "    loss = ((pred - target)**2).sum()\n",
    "\n",
    "    # 4) figure out which weights caused us to miss\n",
    "    loss.backward()\n",
    "\n",
    "    # 5) change those weights\n",
    "    opt.step()\n",
    "\n",
    "    # 6) print our progress\n",
    "    print(loss.get().float_precision())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tatsächlich konnte der Loss verringert werden!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effekt von festgelegter Genauigkeit\n",
    "\n",
    "Es bleibt zu klären wie sehr das Verschlüsseln das Netzwerk-Training beeinfllusst. Da aus theoretischer Sicht die Berechnungen identisch sind, sind auch die finalen Ergebnisse sehr nah am nicht-verschlüsselten Training. Dies kann leicht überprüft werden mit einem unverschlüsselten und deterministischen Training dieses Models. \n",
    "\n",
    "`__init__`:\n",
    "```\n",
    "with torch.no_grad():\n",
    "    self.fc1.weight.set_(torch.tensor([[ 0.0738, -0.2109],[-0.1579,  0.3174]], requires_grad=True))\n",
    "    self.fc1.bias.set_(torch.tensor([0.,0.1], requires_grad=True))\n",
    "    self.fc2.weight.set_(torch.tensor([[-0.5368,  0.7050]], requires_grad=True))\n",
    "    self.fc2.bias.set_(torch.tensor([-0.0343], requires_grad=True))\n",
    "```\n",
    "\n",
    "Die kleinen Unterschiede kommen aus den Rundungen der Float-Zahlen während der Transformation. Die voreingestellte Genauigkeit entspricht `precision_fractional = 3` und kann jederzeit angepasst werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herzlichen Glückwunsch!!! - Zeit, der Community beizutreten! \n",
    "\n",
    "Herzlichen Glückwunsch zum Abschluss dieses Notebook-Tutorials! Wenn es Ihnen gefallen hat und Sie sich der Bewegung zur Wahrung der Privatsphäre, zum dezentralisiertenen Besitz von KI und der KI-Lieferkette (Daten) anschließen möchten, können Sie dies auf folgende Weise tun! \n",
    "\n",
    "### PySyft auf GitHub einen Stern geben! \n",
    "\n",
    "Der einfachste Weg, unserer Community zu helfen, besteht darin, die GitHub-Repos mit Sternen auszuzeichnen! Dies hilft, das Bewusstsein für die coolen Tools zu schärfen, die wir bauen. \n",
    "\n",
    "- [Gib PySyft einen Stern](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Mach mit bei Slack! \n",
    "\n",
    "Der beste Weg, um über die neuesten Entwicklungen auf dem Laufenden zu bleiben, ist, sich unserer Community anzuschließen! Sie können dies tun, indem Sie das Formular unter [http://slack.openmined.org](http://slack.openmined.org) ausfüllen.\n",
    "\n",
    "### Treten Sie einem Code-Projekt bei! \n",
    "\n",
    "Der beste Weg, um zu unserer Community beizutragen, besteht darin, Entwickler zu werden! Sie können jederzeit zur PySyft GitHub Issues-Seite gehen und nach \"Projects\" filtern. Dies zeigt Ihnen alle Top-Level-Tickets und gibt einen Überblick darüber, an welchen Projekten Sie teilnehmen können! Wenn Sie nicht an einem Projekt teilnehmen möchten, aber ein wenig programmieren möchten, können Sie auch nach weiteren \"einmaligen\" Miniprojekten suchen, indem Sie nach GitHub-Problemen suchen, die als \"good first issue\" gekennzeichnet sind. \n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Spenden\n",
    "\n",
    "Wenn Sie keine Zeit haben, zu unserer Codebase beizutragen, aber dennoch Unterstützung leisten möchten, können Sie auch Unterstützer unseres Open Collective werden. Alle Spenden fließen in unser Webhosting und andere Community-Ausgaben wie Hackathons und Meetups! \n",
    "\n",
    " - [OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
